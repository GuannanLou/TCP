{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from fitness import get_fitness\n",
    "from models.Kriging import Kriging\n",
    "from models.PR import Polynomial_Regression as PR\n",
    "# from models.RBF import Model as RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Curve Road\n",
    "data_folders = [\n",
    "    # '../data/routes_short_2023-05-12|17:04:09/', #814\n",
    "    # '../data/routes_short_2023-05-26|17:51:48/', #721\n",
    "    '../data/routes_short_2023-06-06|18:33:36/', #916 95% Route Finish Threshold\n",
    "    '../data/routes_short_2023-06-07|14:26:32/', #727 95% Route Finish Threshold\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1635, 14)\n"
     ]
    }
   ],
   "source": [
    "scenario_header = [\"cloudiness\",\n",
    "                   \"precipitation\",\n",
    "                   \"precipitation_deposits\",\n",
    "                   \"wind_intensity\",\n",
    "                   \"sun_azimuth_angle\",\n",
    "                   \"sun_altitude_angle\",\n",
    "                   \"fog_density\",\n",
    "                   \"wetness\",\n",
    "                   \"fog_falloff\",\n",
    "                   \"vehicle_infront\", \n",
    "                   \"vehicle_opposite\", \n",
    "                   \"vehicle_side\",\n",
    "                   \"start_offset\",\n",
    "                   \"end_offset\"]\n",
    "\n",
    "scenarios = pd.read_csv(data_folders[0]+'scenario.csv',names=scenario_header)\n",
    "for i in range(1, len(data_folders)):\n",
    "    scenarios = pd.concat([scenarios, pd.read_csv(data_folders[i]+'scenario.csv',names=scenario_header)])\n",
    "print(scenarios.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1635, 4)\n"
     ]
    }
   ],
   "source": [
    "select_criterions = [\"RouteCompletionTest\", \n",
    "                     \"CollisionTest\", \n",
    "                     \"OutsideRouteLanesTest\", \n",
    "                     \"Timeout\"]\n",
    "\n",
    "fitness = get_fitness(data_folders[0])\n",
    "for i in range(1, len(data_folders)):\n",
    "    fitness = pd.concat([fitness, get_fitness(data_folders[i])])\n",
    "\n",
    "fitness = fitness[select_criterions]\n",
    "print(fitness.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class FitnessDataset(Dataset):\n",
    "    def __init__(self, scenario_vectors, fitness_results):\n",
    "        self.data = torch.from_numpy(scenario_vectors).float()\n",
    "        self.label = torch.from_numpy(fitness_results).float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.label))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(14, 32)\n",
    "        # self.fc2 = nn.Linear(32, 64)\n",
    "        # self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        # x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, log=True):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        # print(pred.shape, y.shape)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if log:\n",
    "            if batch % 50 == 0:\n",
    "                loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            # print(pred.argmax(axis=1))\n",
    "            # print(y.argmax(axis=1))\n",
    "            # print()\n",
    "            # correct += explained_variance_score(pred.item(), y.item())\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    # correct /= size\n",
    "    # print(f\"Test Error: \\n EVS: {(correct):>0.3f}, Avg loss: {test_loss:>8f} \\n\")\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "def test_all(data, label, model, loss_fn, log=True):\n",
    "    test_loss, EVS, corr = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(torch.tensor(data).float())\n",
    "        test_loss += loss_fn(pred, torch.tensor(label).float()).item()\n",
    "\n",
    "        pred = pred.detach().numpy().reshape(label.shape[0])\n",
    "        pred[pred>1]=1\n",
    "        pred[pred<0]=0\n",
    "\n",
    "        EVS = explained_variance_score(label.reshape(label.shape[0]), pred).round(3)\n",
    "        corr = np.corrcoef(label.reshape(label.shape[0]), pred)[0,1].round(3)\n",
    "        # print(pred.argmax(axis=1))\n",
    "        # print(y.argmax(axis=1))\n",
    "        # print()\n",
    "        # correct += explained_variance_score(pred.item(), y.item())\n",
    "\n",
    "    \n",
    "    # correct /= size\n",
    "    # print(f\"Test Error: \\n EVS: {(correct):>0.3f}, Avg loss: {test_loss:>8f} \\n\")\n",
    "    if log:\n",
    "        print(f\"MSE loss: {test_loss:>8f}, EVS: {EVS:>4f}, corr: {corr:>4f} \\n\")\n",
    "\n",
    "    return test_loss,EVS,corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([16, 14])\n",
      "Labels batch shape: torch.Size([16, 1])\n",
      "Label: tensor([1.])\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.911556  [   16/ 1095]\n",
      "loss: 0.125044  [  816/ 1095]\n",
      "MSE loss: 0.077414, EVS: -0.149000, corr: -0.100000 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.054645  [   16/ 1095]\n",
      "loss: 0.035071  [  816/ 1095]\n",
      "MSE loss: 0.053767, EVS: 0.211000, corr: 0.464000 \n",
      "\n",
      "(0.237, 0.502)\n",
      "Done!\n",
      "\n",
      "\n",
      "Feature batch shape: torch.Size([16, 14])\n",
      "Labels batch shape: torch.Size([16, 1])\n",
      "Label: tensor([0.3980])\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.697140  [   16/ 1095]\n",
      "loss: 0.150407  [  816/ 1095]\n",
      "MSE loss: 0.118869, EVS: 0.042000, corr: 0.205000 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.046048  [   16/ 1095]\n",
      "loss: 0.027678  [  816/ 1095]\n",
      "MSE loss: 0.063095, EVS: 0.506000, corr: 0.712000 \n",
      "\n",
      "(0.52, 0.721)\n",
      "Done!\n",
      "\n",
      "\n",
      "Feature batch shape: torch.Size([16, 14])\n",
      "Labels batch shape: torch.Size([16, 1])\n",
      "Label: tensor([0.8005])\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.682282  [   16/ 1095]\n",
      "loss: 0.034636  [  816/ 1095]\n",
      "MSE loss: 0.026759, EVS: -0.268000, corr: -0.007000 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.006245  [   16/ 1095]\n",
      "loss: 0.011284  [  816/ 1095]\n",
      "MSE loss: 0.014192, EVS: 0.317000, corr: 0.569000 \n",
      "\n",
      "(0.336, 0.582)\n",
      "Done!\n",
      "\n",
      "\n",
      "Feature batch shape: torch.Size([16, 14])\n",
      "Labels batch shape: torch.Size([16, 1])\n",
      "Label: tensor([1.])\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.861366  [   16/ 1095]\n",
      "loss: 0.120836  [  816/ 1095]\n",
      "MSE loss: 0.151040, EVS: -0.067000, corr: -0.076000 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.099393  [   16/ 1095]\n",
      "loss: 0.147126  [  816/ 1095]\n",
      "MSE loss: 0.136883, EVS: 0.046000, corr: 0.245000 \n",
      "\n",
      "(0.076, 0.279)\n",
      "Done!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "models = []\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    scenario_criterion = pd.concat([scenarios, fitness],axis=1)\n",
    "    scenario_vectors = scenario_criterion[scenario_criterion.columns.tolist()[:14]].to_numpy()\n",
    "    fitness_results = scenario_criterion[scenario_criterion.columns.tolist()[14:]].to_numpy()\n",
    "    fitness_results = fitness_results[:,[i]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scenario_vectors, fitness_results, test_size=0.33, random_state=14159)\n",
    "    train_data = FitnessDataset(X_train, y_train)\n",
    "    test_data = FitnessDataset(X_test, y_test)\n",
    "\n",
    "\n",
    "    train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "    # Display image and label.\n",
    "    train_features, train_labels = next(iter(train_dataloader))\n",
    "    print(f\"Feature batch shape: {train_features.size()}\")\n",
    "    print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "    label = train_labels[0]\n",
    "    print(f\"Label: {label}\")\n",
    "\n",
    "    mlp = MLP()\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(mlp.parameters(), lr=0.005, momentum=0.9)\n",
    "    # optimizer = optim.Adam(mlp.parameters(), lr=0.005)\n",
    "\n",
    "    epochs = 200\n",
    "    best_model = None\n",
    "    best_result = (0, 0)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        log = True if t%100 == 0 else False\n",
    "        if log:\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, mlp, criterion, optimizer, log)\n",
    "        # test_loop(test_dataloader, mlp, criterion)\n",
    "        _,EVS,corr = test_all(X_test, y_test, mlp, criterion, log)\n",
    "        if corr > best_result[1]:\n",
    "            best_result = (EVS,corr)\n",
    "            best_model = (mlp,best_result)\n",
    "    \n",
    "    print(best_result)\n",
    "    models.append(best_model)\n",
    "    print(\"Done!\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(MLP(\n",
       "    (fc1): Linear(in_features=14, out_features=32, bias=True)\n",
       "    (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  ),\n",
       "  (0.237, 0.502)),\n",
       " (MLP(\n",
       "    (fc1): Linear(in_features=14, out_features=32, bias=True)\n",
       "    (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  ),\n",
       "  (0.52, 0.721)),\n",
       " (MLP(\n",
       "    (fc1): Linear(in_features=14, out_features=32, bias=True)\n",
       "    (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  ),\n",
       "  (0.336, 0.582)),\n",
       " (MLP(\n",
       "    (fc1): Linear(in_features=14, out_features=32, bias=True)\n",
       "    (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  ),\n",
       "  (0.076, 0.279))]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "for i, certion_label in enumerate([\"RouteCompletionTest\", \"CollisionTest\", \"OutsideRouteLanesTest\", \"Timeout\"]):\n",
    "    joblib.dump(models, 'models/regression-MLP-{}.pkl'.format(certion_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
